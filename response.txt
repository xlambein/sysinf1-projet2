À la review #105A:

# Qualité du code
- Nous n'estimons pas devoir être responsables de memory leaks dans une librairie externe qui nous a été imposée. La solution raisonnable dans ce cas aurait été de changer de librairie, ce que nous n'avons pas pu faire.
- Nous avons fourni avec la soumission un bon nombre de fichiers de test indiqués dans le README qui ne produisent pas de deadlock. L'affirmation que le programme entre en deadlock « à chaque fois que je lui passe un fichier un peu plus gros que les fichiers de tests reçus sur iCampus » nous paraît donc étrange.
- La description du deadlock est très vague : il aurait été bien de préciser un fichier d'entrée qui l'entraîne, ou des conditions plus précise, en particulier à quel endroit se trouvent bloqués les factorizers pendant ce temps, un deadlock étant rarement l'action d'un seul thread. De plus, le système de synchronisation de type rendez-vous des threads a été testé de nombreuses fois sur des fichiers avec énormément de nombres, sans montrer une seule faiblesse.
- La description du livelock est aussi sans fichier d'exemple et très vague. Il n'est pas précisé dans quelles conditions une valeur 1 pourrait se retrouver comme argument de cette fonction. C'est impossible depuis factorizer.c:42 car i est toujours plus grand ou égal à 2 ; c'est testé explicitement en main.c:295 avant l'appel en main.c:302 ; et un argument 1 en reader.c:47 voudrait dire qu'un facteur 1 s'est glissé dans la prime_list, ce qui est de nouveau évité par la condition en main.c:295.
- L'argument « surtout qu'ils sont bien passés dans la deuxième review que j'ai rédigée » est plutôt faible : que des fichiers incorrects soient gérés par chance par un programme n'en fait pas des fichiers valides par rapport aux garanties de l'énoncé.
- De manière générale, les descriptions de deadlocks/livelocks sont fort lacunaires, et en l'absence de fichiers d'entrée correspondants, cet élément de la review ne nous est d'aucune aide en nous oblige à croire sur parole un défaut annoncé de notre programme que nous n'avons jamais rencontré dans nos nombreux tests, et pour lequel nous ne pouvons rien faire. Si le reviewer pouvait nous envoyer ces fichiers par mail (victor.lecomte@student.uclouvain.be ou xavier.lambein@student.uclouvain.be) ça nous aiderait beaucoup et nous adapterions la réponse en conséquence.
- Enfin, concernant la remarque sur le fait que notre programme est « gros », nous avons précisé dans le rapport que nous avons choisi cette approche de réutilisation de facteurs premiers pour le challenge de synchronisation qu'il représente. Cela ne devrait donc pas être une surprise que le programme est conséquent. Si le reviewer a des suggestions à faire pour rendre notre programme plus simple, nous serions réellement intéressés de les entendre. :)

# Analyse de performances
- Par rapport à la remarque « Au final, avec un input généré au hasard, on peut conclure que le gain de performances en fonction du nombre de threads est laissé au hasard et on ne peut donc pas deviner à l'avance s'il faut mettre plus ou moins de threads si l'on veut que notre programme soit plus ou moins rapide. » : La performance de notre algorithme dépend directement de la taille des nombres d'entrée et de la taille et la répartition des facteurs premiers dans ces nombres. La section d'analyse de performances, très développée dans notre rapport, est centrée sur ce problème de prédire et expliquer les performances de notre programme dans différents cas. Dire que les performances sont laissées au hasard montre une mécompréhension de cette analyse, et au final du fonctionnement et de la conception de notre programme. Dans le deuxième cas de l'analyse dans notre rapport, la réaction en chaîne se fait avec « haute probabilité » pour un input aléatoire, et revient au troisième cas dans le pire cas. Ce genre de comportement, qui a pu provoquer la mécompréhension du reviewer, est en fait typique d'un grand nombre d'algorithmes connus comme le quicksort, qui a un pire cas en O(n^2), et qui est pourtant utilisé pour son cas moyen en O(n*log(n)) dans la STL C++.
- Comme mentionné dans le rapport, il nous a été assuré lors de la réunion d'architecture que la factorisation serait la partie demandant le plus de calculs dans le programme. Nous avons donc en toute logique parallélisé cette partie. Dans les cas de tests ou cette partie est en effet le facteur limitant, cette parallélisation marche très bien, et nous considérons que nous avons atteint notre objectif. Nous considérons que les cas où les nombres sont trop petits comme le premier cas que nous avons exploré dans notre rapport ne font pas partie des cas à prendre en compte car ils ne respectent pas les hypothèses qui nous ont été données. En effet, si le problème à résoudre avait été simple (petits nombres et facteurs premiers), nous aurions utilisé une approche simple basée sur la précalculation pour le résoudre, mais ç'aurait été un problème différent.
- À nouveau, nous insistons sur le fait que des fichiers de test plus grands que ceux d'iCampus avaient bel et bien été donnés dans l'archive, tel qu'expliqué dans le fichier README.

# Architecture
- La valeur de la variable to_fact est uniquement bloquée quand un facteur est trouvé, ce qui un événement très rare par rapport à la taille du nombre. Nous sommes donc un peu perplexes par rapport à l'existence d'un bottleneck sur cette variable. Le fait que les threads travaillent sur le même nombre apporte aussi un gain significatif en temps : dès qu'un thread parvient à diviser le nombre, les autres threads le prennent en compte automatiquement et ne doivent plus tenter de diviser aussi loin qu'ils devaient a priori.
- Nous avons choisi de ne pas utiliser le modèle producteur-consommateur (voir la première section de notre rapport) pour ne pas que ce projet se résume à tester si nous savons l'implémenter correctement. Et nous avons obtenu des performances très satisfaisantes.
- « on aurait pu certainement éviter de répéter le même travail, de parcourir plusieurs fois la waiting list pour tester des divisions en utilisant une autre architecture » : nous sommes obligés de parcourir cette liste à chaque facteur premier distinct trouvé pour vérifier que sa découverte n'aide pas à la factorisation des nombres, ce qui est notre principe de conception de base. Nous sommes curieux quant à l'architecture alternative suggérée par le reviewer.
- La répartition entre les threads est plutôt simple : les factorizers se chargent de trouver de nouveaux facteurs, tandis que main se charge d'utiliser ces facteurs, et reader se charge d'ajouter de nouveaux facteurs. Il faut simplement qu'ils s'assurent en faisant ces opérations de maintenir la structure des listes. L'argument "-maxthreads" reste pertinent car il décrit le nombre de threads de la seule partie de la factorisation qui est parallélisée, la structure que main et les readers utilisent étant synchronisée.
- « Je pense qu'il y a eu de bonnes idées dans cette architecture mais qu'elles ont été mal exploitées et mises en oeuvre. » : de nouveau, nous accueillerions avec plaisir des suggestions à ce sujet. :)

Aux reviews #105B-#105C: rien à dire. ;)

À la review #105D:

# Qualité du code
- En effet, nous aurions dû ajouter une condition pour vérifier qu'il y avait au moins un flux d'entrée, bonne remarque !

# Analyse de performances
- Les fichiers que nous avons chronométrés pour le rapport étaient documentés et inclus dans l'archive remises. Nous avons aussi fourni aussi un générateur très souple et très complet pour créer différent types de fichiers d'entrée.
- En effet, les fichiers 4k et 40k fournis par Mathieu Xhonneux (http://zashas.net/systinfo/) comprennent simplement les 4k et 40k plus petits facteurs premiers, dans l'ordre, et écrits en double à l'exception du dernier.

# Architecture
- La dernière remarque est très pertinente, c'est en effet une question d'interprétation ! Ce que nous voulions dire est que nous considérions que la factorisation serait avec une marge significative la partie la plus calculatoire du problème, et que les fichiers de tests seraient aussi difficiles que l'énoncé le laissait entendre, c'est-à-dire avec des nombres proches de 2^64 et des facteurs premiers proches de 2^32. Dans ces conditions, notre programme est en effet très efficace et très bien parallélisé pour tout fichier prenant un temps à peu près raisonnable à finir.

À la review #105E:

# Qualité du code
- Les deux remarques négatives sont tout à fait correctes : ces points auraient en effet demandé des explications dans le code ou dans le rapport.

# Architecture
- Les memory leaks mentionnées sont dues à la librairie curl que nous avons été obligés d'utiliser. ;)
